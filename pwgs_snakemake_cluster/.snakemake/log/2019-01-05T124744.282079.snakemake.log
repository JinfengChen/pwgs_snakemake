Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	5	run_final_parser
	6

[Sat Jan  5 12:47:45 2019]
rule run_final_parser:
    input: /data/browna6/evolution/pwgs/phyloinputs/egfr_exome/CL0038/CL0038_T1D_E.cnvs.txt, /data/browna6/evolution/pwgs/phyloinputs/egfr_exome/CL0038/CL0038_T1D_E.ssm.txt, /data/browna6/evolution/pwgs/pwgs_output/witness/data/CL0038/CL0038_T1D_E.summ.json, /data/browna6/evolution/pwgs/pwgs_output/witness/data/CL0038/CL0038_T1D_E.mutass.zip
    output: /data/browna6/evolution/pwgs/phyloresults_parsed/CL0038/CL0038_T1D_E/tree_likelihoods.txt
    jobid: 2
    wildcards: patient=CL0038, sample=CL0038_T1D_E

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /spin1/users/browna6/pwgs_snakemake/.snakemake/log/2019-01-05T124744.282079.snakemake.log
